# Building a Neural Network from Scratch
## Project Overview
A neural network is a constellation of neurons or nodes arranged in layers. Each node takes in an input, processes that input based on the mathematical function in the particular layer it is situated and produces an interim or final output - depending on where its layered in the network.

This project disambiguates what happens in a neural network by building one. The project
* examines the theory behind a n-layered neural network
* builds a 2 layer neural network from scratch using ReLU and Softmax as an activation function
* Evaluates accuracy on training, validation and test results with the Fashion MNIST dataset

For a detailed explanation on the theory used for this computation and an overview on how machines learn, check out the accompanying [article on medium](https://medium.com/@ayoakinkugbe/linear-regression-from-scratch-using-matrices-991df6e28f62)

### Code
You can find the code for this project [here](https://github.com/ayoakin/LinearRegression/blob/main/LinearRegressionScratch.ipynb).

File overview:

* `LinearRegressionScratch.ipynb` - the full code from this project


## Environment Setup

### Installation
To follow this project, please install the following locally:

* Python 3.8+
* Python packages
  * pandas
  * numpy
  * matplotlib

### Data

The data used for this implementation is the Fashion MNIST dataset originally on [Kaggle](https://www.kaggle.com/datasets/zalando-research/fashionmnist).

You can download the exact file used in this project here:

* [Salary_Data.csv](https://github.com/ayoakin/LinearRegression/blob/main/Salary_Data.csv) - the salary  data that we use in this project.
